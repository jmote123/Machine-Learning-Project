---
title: "Machine Learning Project"
---


**Your Name**: Jyoti Mote
**Your G Number**: G01287487



```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)
library(tidyverse)
library(tidymodels)
library(dplyr)
library(ggplot2)
library(recipes)
library(rsample)
library(readr)                   
library(tidyr)
library(vip)
library(rpart.plot)
library(grid)
library(discrim)
library(ranger)
library(yardstick)

credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))
view(credit_card_df)

```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**:

1. How is education effecting the customer status?

**Answer**:

First we analyzed the data the total number of people who have credit account is less for the people with doctorate degree and more for people with masters and associate degree, by observing the graph more deeply we can say that when comparing the proportions ratio of active users  with bachelors is a little higher than customers with other educational backgrounds. The proportion ratio of closed accounts with doctorate is higher.

```{r}

#BAR PLOT

education_df <- credit_card_df %>% group_by(education,customer_status) %>% summarize(Count= n(),.groups = 'drop')

#summary data

education_df
View(education_df)

#plot

ggplot(education_df, aes(fill=customer_status, y=Count, x=education)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_text(aes(label = round(Count, 1)), 
            position = position_dodge(0.9),
            color="white",vjust = 1.2,hjust = 0.5)+
  scale_fill_manual(values = c("turquoise4","goldenrod"))
  

```



# Question 2


**Question**:

2. How does utilization ratio effect customer status?

**Answer**:

We can observe that when the utilization ratio is the least or zero, the count for closed account is highest. and when the utilization ratio is highest the count of closed account is the least. hence we can say that less utilization ratio is one of the parameters for closed account.

```{r}

#plot

ggplot(credit_card_df, aes(x=utilization_ratio, group=customer_status, fill=customer_status)) +
  geom_density(adjust=1.5, alpha=.4) +
  facet_wrap(~customer_status) +
  scale_fill_manual(values = c("turquoise4","goldenrod"))+
  theme()


```


# Question 3


**Question**:

3. Which employment status has highest and least number of closed account and active account?

**Answer**:

The employment status which has least number of closed account is self employed, and the highest number of closed account for an employment status is part time.
The maximum number of active account is full time, and least number of active account is self employed.
By this analysis we can say that people working as part time has highest closed account as part time employees have less income, which might lead to the closing of the credit account. 


```{r}

#Summary Data
emp_df <- credit_card_df %>% group_by(employment_status,customer_status)%>% summarize(Count= n())
emp_df 
View(emp_df)

#plot
ggplot(emp_df, aes(x=employment_status, y=Count, size = customer_status)) +
  geom_point(alpha=0.7)



```



# Question 4


**Question**:

4.How is credit limit related to customer status?

**Answer**:

The average credit limit of the customers who have closed their credit account is less compared to the once who have an active account. Less credit limit can also be one of factors influencing the closing of the account.

```{r}

#Data Summary
credlimit_df <- credit_card_df %>% group_by(customer_status)%>% summarise(Mean_credit_limit = mean(credit_limit, na.rm=TRUE))
credlimit_df 
view(credlimit_df)

#plot
ggplot(credit_card_df, aes(x=customer_status, y=credit_limit, fill=customer_status)) + 
  geom_boxplot(alpha=0.3) +
  theme(legend.position="none") +
  scale_fill_brewer(palette="Dark2")





```



# Question 5


**Question**:

5.Does income have an effect on the customer status?

**Answer**:
The total number of customers who have closed the accounts are 2092 and active accounts are 2535.
The average income of closed account is 61601.51, and active account is 62842.83.
The minimum income for closed account is 30198 and active account is 30094. 
The maximum income for cloased account is 168522 and for active account is 166225.
By the numbers we can say that though the average income of the customers who closed their account is less compared to active account. They might end up spending more than what they earn if they have a credit account, hence leading to closing the account and income also plays an vital role in the customer status.

```{r}

#Data Summary
income_df <-credit_card_df %>% group_by(customer_status) %>% 
  summarise(count = n(),
            avg_income = mean(income),
            min_income = min(income),
            max_income = max(income))
income_df
view(income_df)


```


```


# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data





# Data Split/create recipie

```{r}
#Data Split into traing and testing

set.seed(314)

data_split <- initial_split(credit_card_df, prop = 0.75, 
                            strata = customer_status)

data_training <- data_split %>% training()

data_test <- data_split %>% testing()

# create folds
set.seed(314)

customerstatus_folds <- vfold_cv(data_training, v = 5)

#create a recipie

customerstatus_recipe <- recipe(customer_status ~ ., data = data_training) %>% 
  step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

#check if feature engineering is correct

customerstatus_recipe %>% 
  prep(training = data_training) %>% 
  bake(new_data = NULL)


```



# Model 1: Logistic Regression

```{r}


#model specification

logistic_specification <- logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')

logistic_specification


#create work flow

logistic_wf <- workflow() %>% 
  add_model(logistic_specification) %>% 
  add_recipe(customerstatus_recipe)


#Fit model

logistic_fit <- logistic_wf %>% 
  last_fit(split = data_split)



logistic_results <-  logistic_fit %>% 
  collect_predictions()





#ROC Curve

## ROC Curve
roc_curve(logistic_results, 
          truth = customer_status, 
          estimate = .pred_closed_account) %>% 
  autoplot()

# ROC AUC
roc_auc(logistic_results, 
        truth = customer_status,
        .pred_closed_account)


# Confusion Matrix
conf_mat(logistic_results, 
         truth = customer_status, 
         estimate = customer_status)

logisticregression_predictions <- logistic_fit %>% collect_predictions()

#performace

metricss <- metric_set(accuracy, sens, spec, roc_auc)
metricss(logistic_results, truth = customer_status, estimate = .pred_class, .pred_closed_account)




```




# Model 2: Decision Tree

```{r}


#model specification
dtree_specification <- decision_tree(cost_complexity = tune(),
                            tree_depth = tune(),
                            min_n = tune()) %>% 
  set_engine('rpart') %>% 
  set_mode('classification')

#workflow

dtree_workflow <- workflow() %>% 
  add_model(dtree_specification) %>% 
  add_recipe(customerstatus_recipe)


## Create a grid of hyperparameter values to test
dtree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)


# View grid
dtree_grid

#grid using parameter

dtree_grid <- grid_regular(parameters(dtree_specification), 
                          levels = 2)

#view dtree_grid_param

dtree_grid



## Tune decision tree workflow
set.seed(314)

dtree_tuning <- dtree_workflow %>% 
  tune_grid(resamples = customerstatus_folds,
            grid = dtree_grid)


## Show the top 5 best models based on roc_auc metric
dtree_tuning %>% show_best('roc_auc')

## Select best model based on roc_auc
bestmodel_dtree <- dtree_tuning %>% 
  select_best(metric = 'roc_auc')

# View the best tree parameters
bestmodel_dtree

finaldtree_workflow <- dtree_workflow %>% 
  finalize_workflow(bestmodel_dtree)

finaldtree_workflow

#fit the model
dtree_wffit <- finaldtree_workflow %>% 
  fit(data = data_training)


#explore trained model
tree_fit <- dtree_wffit %>% 
  extract_fit_parsnip()


#variable importance
vip(tree_fit)


rpart.plot(tree_fit$fit, roundint = FALSE, extra = 2)


#train and evalvate with lastfit
dtree_lastfit <- finaldtree_workflow %>% 
  last_fit(data_split)


#collect metrics
dtree_lastfit %>% collect_metrics()


#ROC Curve

dtree_lastfit %>% collect_predictions() %>% 
  roc_curve(truth  = customer_status, estimate = .pred_closed_account) %>% 
  autoplot()


#confusion matrix

dtree_predictions <- dtree_lastfit %>% collect_predictions()

conf_mat(dtree_predictions, truth = customer_status, estimate = .pred_class)

#performace 

metricss <- metric_set(accuracy, sens, spec, roc_auc)
metricss(dtree_predictions, truth = customer_status, estimate = .pred_class, .pred_closed_account)


```





# Model 3: KNN Classification

```{r}

#model specification
knn_specification <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine('kknn') %>% 
  set_mode('classification')

#Create workflow

knn_wf <- workflow() %>% 
  add_model(knn_specification) %>% 
  add_recipe(customerstatus_recipe)

# Create a grid of hyperparameter values to test
knn_grid <- tibble(neighbors = c(10, 15, 25, 45, 60, 80, 100, 120, 140, 180))


## Tune  workflow
set.seed(314)

knn_tuning <- knn_wf %>% 
  tune_grid(resamples = customerstatus_folds,
            grid = knn_grid)


## Select best model based on roc_auc
best_k <- knn_tuning %>% 
  select_best(metric = 'roc_auc')


## Finalize workflow by adding the best performing model

final_knn_wf <- knn_wf %>% 
  finalize_workflow(best_k)


knn_fit <- final_knn_wf %>% 
  last_fit(split = data_split)


knn_results <-  knn_fit %>% 
  collect_predictions()


## ROC Curve
roc_curve(knn_results, 
          truth = customer_status, 
          estimate = .pred_closed_account) %>% 
  autoplot()

# ROC AUC
roc_auc(knn_results, 
        truth = customer_status, 
        .pred_closed_account)

# Confusion Matrix
conf_mat(knn_results, 
         truth = customer_status, 
         estimate = .pred_class)


#performace

metricss <- metric_set(accuracy, sens, spec, roc_auc)
metricss(knn_results, truth = customer_status, estimate = .pred_class, .pred_closed_account)



```




# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?

<br>

2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section

<br>

3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a bank with limited knowledge of machine learning.

<br>

4. Your recommendations to the bank on how to reduce the number of customers closing their credit card accounts 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**

Add your summary here. Please do not place your text within R code chunks.


The company is trying to solve the problem of customers closing their credit account. The goal of my analysis is to identify the problems which causes the customers to close their credit accounts and making necessary recommendations to overcome that problem. The questions I am trying to answer are listed below:

1. How is education effecting the customer status?
2. How does utilization ratio effect customer status?
3. Which employment status has highest and least number of closed account and active account?
4.How is credit limit related to customer status?
5.Does income influence the customer status?

Answering these questions matters as the company can investigate these parameters and improve their operations wherever necessary to smoothly function resulting in high profits.

Key Findings:

The credit card data is analyzed to see how various variables are related to the customer status and which parameters effect the closed and active account. First, we analyzed the data the total number of people who have credit account is less for the people with doctorate degree and more for people with masters and associate degree, by observing the graph more deeply we can say that when comparing the proportions ratio of active users with bachelors is a little higher than customers with other educational backgrounds. The proportion ratio of closed accounts with doctorate is higher. Next, we are checking how utilization ratio effects customer status. We can observe that when the utilization ratio is the least or zero, the count for closed account is highest. and when the utilization ratio is highest the count of closed account is the least. hence, we can say that less utilization ratio is one of the parameters for closed account. We can also check the effect of employment status on customer status, The employment status which has least number of closed accounts is self-employed, and the highest number of closed accounts for an employment status is part time. The maximum number of active accounts is full time, and least number of active accounts is self-employed, people working as part time has highest closed account as part time employees have less income, which might lead to the closing of the credit account. The average credit limit of the customers who have closed their credit account is less compared to the once who have an active account. Less credit limit can also be one of factors influencing the closing of the account. The average income of the customers who closed their account is less compared to active account. They might end up spending more than what they earn if they have a credit account, hence leading to closing the account and income also plays a vital role in the customer status.

The best model among Logistic regression, Decision tree, and KNN is decision tree because the accuracy of this model is 89.6 which is greater than the accuracies of the other two models. On observing the sensitivity of the model, we can estimate the probability of a positive test that is if the predicted and true outcome belongs to positive class. The sensitivity of the decision tree is 93.11 which means that the model is able to predict 93 true positives out of every 100 true positives correctly. The specificity of the decision tree is 86.75 which means that the model is able to predict 86.75 true negatives out of every 100 true negatives correctly.


From the above exploratory analysis, we can recommend few changes offering the customers high credit limit, as we have seen customers with less credit limit have a greater number of closed accounts. The bank should encourage the customers to utilize their credit card by providing them with required assistance and offers. Customers with part time employment and low-income customers can be given some benefit like they can be provided with low APR.



